{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re\n",
    "import nltk\n",
    "import heapq\n",
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keybert\n",
      "  Using cached keybert-0.7.0.tar.gz (21 kB)\n",
      "Collecting sentence-transformers>=0.3.8\n",
      "  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in /Users/narin/opt/anaconda3/lib/python3.8/site-packages (from keybert) (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/narin/opt/anaconda3/lib/python3.8/site-packages (from keybert) (1.20.1)\n",
      "Collecting rich>=10.4.0\n",
      "  Using cached rich-13.1.0-py3-none-any.whl (238 kB)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "Collecting typing-extensions<5.0,>=4.0.0\n",
      "  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /Users/narin/opt/anaconda3/lib/python3.8/site-packages (from rich>=10.4.0->keybert) (2.8.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/narin/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.22.2->keybert) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/narin/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.22.2->keybert) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/narin/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.22.2->keybert) (2.1.0)\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Using cached transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: tqdm in /Users/narin/opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers>=0.3.8->keybert) (4.59.0)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-1.13.1-cp38-none-macosx_10_9_x86_64.whl (135.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 135.4 MB 290 kB/s  eta 0:00:01   |██████                          | 25.3 MB 8.0 MB/s eta 0:00:14█                       | 37.8 MB 8.0 MB/s eta 0:00:1392.4 MB 18.2 MB/s eta 0:00:03\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.14.1-cp38-cp38-macosx_10_9_x86_64.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 155.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nltk in /Users/narin/opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers>=0.3.8->keybert) (3.6.1)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp38-cp38-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 86.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "\u001b[K     |████████████████████████████████| 182 kB 16.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /Users/narin/opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (20.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/narin/opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (5.4.1)\n",
      "Requirement already satisfied: filelock in /Users/narin/opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.0.12)\n",
      "Requirement already satisfied: requests in /Users/narin/opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.25.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/narin/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.4.7)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/narin/opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2021.4.4)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp38-cp38-macosx_10_11_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 41.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click in /Users/narin/opt/anaconda3/lib/python3.8/site-packages (from nltk->sentence-transformers>=0.3.8->keybert) (7.1.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/narin/opt/anaconda3/lib/python3.8/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/narin/opt/anaconda3/lib/python3.8/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/narin/opt/anaconda3/lib/python3.8/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/narin/opt/anaconda3/lib/python3.8/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/narin/opt/anaconda3/lib/python3.8/site-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (8.2.0)\n",
      "Building wheels for collected packages: keybert, sentence-transformers\n",
      "  Building wheel for keybert (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keybert: filename=keybert-0.7.0-py3-none-any.whl size=23789 sha256=11ca8f9a93cefa4b2b3614f397752dbb42ecf3b1375b6dff04da70084db9b8c6\n",
      "  Stored in directory: /Users/narin/Library/Caches/pip/wheels/6c/bc/8b/a51bee77aec33895e6c8c236144b4cc10875659c4d2c80f070\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125918 sha256=c7b6337311f0ef2bd7e3f940b333de4ab7d5355ca105df92819f5df5272c0b42\n",
      "  Stored in directory: /Users/narin/Library/Caches/pip/wheels/5e/6f/8c/d88aec621f3f542d26fac0342bef5e693335d125f4e54aeffe\n",
      "Successfully built keybert sentence-transformers\n",
      "Installing collected packages: typing-extensions, torch, tokenizers, huggingface-hub, transformers, torchvision, sentencepiece, commonmark, sentence-transformers, rich, keybert\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "Successfully installed commonmark-0.9.1 huggingface-hub-0.11.1 keybert-0.7.0 rich-13.1.0 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.2 torch-1.13.1 torchvision-0.14.1 transformers-4.25.1 typing-extensions-4.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eng:\n",
    "    def __init__(self,data:list):\n",
    "        self.data_value = data\n",
    "        self.sentence = self.get_sentence()\n",
    "        \n",
    "    def get_sentence(self):\n",
    "        self.sentence_result = self.make_sentence(self.data_value)\n",
    "        return self.sentence_result\n",
    "    def make_sentence(self,list_word):\n",
    "        self.sentence_value = ' '.join(list_word)\n",
    "        return self.sentence_value\n",
    "    def tokenize(self):\n",
    "        self.sentence_list = nltk.sent_tokenize(self.sentence)\n",
    "        return self.sentence_list\n",
    "    def create_formatted_article(self):\n",
    "        # Removing special characters and digits\n",
    "        self.get_sentence()\n",
    "        self.formatted_article_text = re.sub('[^a-zA-Z]', ' ', self.sentence_result )\n",
    "        self.formatted_article_text = re.sub(r'\\s+', ' ', self.formatted_article_text)\n",
    "        return self.formatted_article_text\n",
    "    def find_word_frequencies(self):\n",
    "        self.tokenize()\n",
    "        self.create_formatted_article()\n",
    "        stopwords = nltk.corpus.stopwords.words('english')\n",
    "        self.word_frequencies = {}\n",
    "        for word in nltk.word_tokenize(self.formatted_article_text):\n",
    "            if word not in stopwords:\n",
    "                if word not in self.word_frequencies.keys():\n",
    "                    self.word_frequencies[word] = 1\n",
    "                else:\n",
    "                    self.word_frequencies[word] += 1\n",
    "        return self.word_frequencies\n",
    "    def find_maximum_frequncy(self):\n",
    "        self.find_word_frequencies()\n",
    "        maximum_frequncy = max(self.word_frequencies.values())\n",
    "        for word in self.word_frequencies.keys():\n",
    "            self.word_frequencies[word] = (self.word_frequencies[word]/maximum_frequncy)\n",
    "    def find_sentence_scores(self):\n",
    "        self.sentence_scores = {}\n",
    "        self.tokenize()\n",
    "        self.find_word_frequencies()\n",
    "        for sent in self.sentence_list:\n",
    "            for word in nltk.word_tokenize(sent.lower()):\n",
    "                if word in self.word_frequencies.keys():\n",
    "                    if len(sent.split(' ')) < 30:\n",
    "                        if sent not in self.sentence_scores.keys():\n",
    "                            self.sentence_scores[sent] = self.word_frequencies[word]\n",
    "                        else:\n",
    "                            self.sentence_scores[sent] += self.word_frequencies[word]\n",
    "        return self.sentence_scores\n",
    "    def summary_sentences(self):\n",
    "        self.find_sentence_scores()\n",
    "        self.summary_sentences = heapq.nlargest(5, self.sentence_scores, key=self.sentence_scores.get)\n",
    "        summary = ' '.join(self.summary_sentences)\n",
    "        return self.summary_sentences\n",
    "    def find_keyword(self):\n",
    "        self.get_sentence()\n",
    "        kw_model = KeyBERT()\n",
    "        keywords = kw_model.extract_keywords(self.sentence_result)\n",
    "        return kw_model.extract_keywords(self.sentence_result, keyphrase_ngram_range=(1, 1), stop_words=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = Eng([\"More classified material found at Biden's home\", 'Top secret documents reportedly found in Biden cache', 'Four unanswered questions about the Biden documents', 'How Biden and Trump secret files cases compare', 'Delay in telling public about files may haunt Biden', \"Republicans want to know who visited Biden's homes\", 'The problem with politicians and classified files', 'Biden under investigation', 'How much trouble is the president in over classified documents found at his home?', 'Who is the special counsel in the Biden probe?', 'Special counsel appointed to investigate Biden files', 'Second batch of classified Biden documents found', 'Jill Biden has surgery to remove cancerous skin lesions', \"Biden 'surprised' about classified files discovery\", 'Biden visits US-Mexico border in trip to Texas', 'Western allies to send fighting vehicles to Ukraine', 'What will change with Republicans controlling the House', \"What's actually in the $1.7tn US spending bill?\", \"Zelensky trip shows US doesn't want peace - Russia\", 'Ukraine is alive and kicking, Zelensky tells US'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"More classified material found at Biden's home Top secret documents reportedly found in Biden cache Four unanswered questions about the Biden documents How Biden and Trump secret files cases compare Delay in telling public about files may haunt Biden Republicans want to know who visited Biden's homes The problem with politicians and classified files Biden under investigation How much trouble is the president in over classified documents found at his home? Who is the special counsel in the Biden probe? Special counsel appointed to investigate Biden files Second batch of classified Biden documents found Jill Biden has surgery to remove cancerous skin lesions Biden 'surprised' about classified files discovery Biden visits US-Mexico border in trip to Texas Western allies to send fighting vehicles to Ukraine What will change with Republicans controlling the House What's actually in the $1.7tn US spending bill? Zelensky trip shows US doesn't want peace - Russia Ukraine is alive and kicking, Zelensky tells US\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng.get_sentence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Zelensky trip shows US doesn't want peace - Russia Ukraine is alive and kicking, Zelensky tells US\",\n",
       " 'Who is the special counsel in the Biden probe?']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng.summary_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('biden', 0.4392),\n",
       " ('documents', 0.3501),\n",
       " ('classified', 0.3172),\n",
       " ('politicians', 0.2588),\n",
       " ('files', 0.2574)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng.find_keyword()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f77b640396ee907328d3f2b1dbf7d1073670d4b49ce003bfc4c9fbcbcb50868c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
