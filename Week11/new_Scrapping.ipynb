{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "import unicodedata\n",
    "import pythainlp.util\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "#from pythainlp.summarize import extract_keywords\n",
    "from pythainlp.summarize import summarize\n",
    "import itertools\n",
    "import sqlite3\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "from pythainlp.tag import tag_provinces\n",
    "from pythainlp.tokenize import word_tokenize as tokenizer\n",
    "from datetime import datetime\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class spyder:\n",
    "    def __init__( self ,links,base_url,depth ):\n",
    "        self.base_url = base_url\n",
    "        target_links={}\n",
    "        for i in links:\n",
    "            target_links[i]=0 \n",
    "        self.target_links = target_links\n",
    "        self.depth = depth\n",
    "    \n",
    "    def get_crawler(self):\n",
    "        self.result_crawler = self.crawl(self.base_url,self.depth,0,set())\n",
    "        return self.result_crawler\n",
    "    \n",
    "    def get_check_domain(self):\n",
    "        self.check_domain_result = self.check_domain(self.base_url,self.get_crawler())\n",
    "        return self.check_domain_result\n",
    "    \n",
    "    def get_check_not_domain(self):\n",
    "        self.check_not_domain_result = self.check_not_domain(self.base_url,self.get_crawler())   \n",
    "        return self.check_not_domain_result\n",
    "    \n",
    "    def get_check_ref(self):\n",
    "        self.check_ref_result = self.check_ref(self.get_check_not_domain(),self.target_links)\n",
    "        return self.check_ref_result\n",
    "    \n",
    "    def get_all(self):\n",
    "        crawl = self.crawl(self.base_url,self.depth,0,set())\n",
    "        check_domain =  self.check_domain(self.base_url,crawl) \n",
    "        check_not_domain = self.check_not_domain(self.base_url,crawl)\n",
    "        check_ref = self.check_ref(check_not_domain,self.target_links)\n",
    "        return check_domain,check_ref\n",
    "    \n",
    "    def crawl(self,url,n, depth,visited):\n",
    "        if depth < n :\n",
    "            visited.add(url)\n",
    "            headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246\"}\n",
    "            time.sleep(0.3)\n",
    "            response = requests.get(url,headers=headers)\n",
    "            try:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            except:\n",
    "                soup = BeautifulSoup(response.text, 'lxml')\n",
    "            links = soup.find_all('a')\n",
    "            links = [link.get('href') for link in links if link.get('href') and not link.get('href').startswith('#')]\n",
    "            links = [urljoin(url, link) for link in links if link]\n",
    "\n",
    "            for link in links:\n",
    "                if link not in visited:\n",
    "                    link = link.replace(' ','')\n",
    "                    visited.add(link)\n",
    "                    if link.startswith(url):\n",
    "                        self.crawl(link,n=n,depth=depth+1, visited=visited)\n",
    "        return visited\n",
    "    \n",
    "    def check_domain(self,base_url,links):\n",
    "        result= set()\n",
    "        for link in links :\n",
    "            if link.startswith(base_url):\n",
    "                result.add(link)\n",
    "        return result\n",
    "    \n",
    "    def check_not_domain(self,base_url,links):\n",
    "        result= set()\n",
    "        for link in links :\n",
    "            if not link.startswith(base_url):\n",
    "                result.add(link)\n",
    "        return result\n",
    "    \n",
    "    def check_ref(self,links,target_links):\n",
    "        for i in links:\n",
    "            for j in target_links:\n",
    "                if i.startswith(j):\n",
    "                    target_links[j]+=1\n",
    "        return target_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'https://www.nytimes.com/2023/03/18/opinion/modi-india.html', 'https://www.nytco.com/careers/', 'https://www.nytimes.com/2023/03/17/podcasts/oprah-winfrey-book-club-face-recognition-software.html', 'https://theathletic.com/4321678/2023/03/17/edwin-diaz-injury-return-2023/', 'https://www.nytimes.com/section/style', 'https://www.nytimes.com/2023/03/16/arts/music/piotr-beczala-lohengrin-met-opera.html', 'https://www.nytimes.com/international/?action=click&region=Editions&pgtype=Homepage', 'https://www.nytimes.com/crosswords', 'https://theathletic.com/4320676/2023/03/18/top-free-agents-available-nfl/', 'https://www.nytimes.com/privacy/privacy-policy', 'https://www.nytimes.com/ca/?action=click&region=Footer&pgtype=Homepage', 'https://www.nytimes.com/2023/03/18/opinion/letters/college-conservatives.html', 'https://nytmediakit.com/', 'https://www.nytimes.com/section/todayspaper', 'https://www.nytimes.com/section/nyregion', 'https://www.nytimes.com/section/travel', 'https://help.nytimes.com/hc/en-us/articles/115015385887-Contact-Us', 'https://www.nytimes.com/2023/03/17/nyregion/najee-seabrooks-patterson-police-nj.html', 'https://www.nytimes.com/2023/03/17/opinion/lawyers-debt-monopoly-advice.html', 'https://theathletic.com/tag/ncaa-tournament/', 'https://cn.nytimes.com', 'https://theathletic.com/4320837/2023/03/17/march-madness-upsets-second-round/', 'https://www.nytimes.com/section/science', 'https://www.nytimes.com/2023/03/17/arts/music/jim-gordon-dead.html', 'https://www.nytimes.com/2023/03/18/business/zoom-friends-socializing.html', 'https://www.nytimes.com/puzzles/spelling-bee', 'https://www.nytimes.com/2023/03/17/sports/ncaabasketball/fairleigh-dickinson-purdue-upset.html', 'https://www.nytimes.com/2023/03/17/arts/music/met-opera-anna-netrebko.html', 'https://cooking.nytimes.com/', 'https://www.nytimes.com/section/arts', 'https://theathletic.com/live-blogs/ncaa-tournament-second-round-live-scores-results-bracket/6VoJ2DDdgkee/', 'https://www.nytimes.com/2023/03/17/magazine/corpse-photos-ethics.html', 'https://www.nytimes.com/subscription?campaignId=37WXW', 'https://www.nytimes.com/interactive/2023/03/16/briefing/the-weekender.html', 'https://www.nytimes.com/es/', 'https://www.nytimes.com/puzzles/letter-boxed', 'https://www.nytimes.com/2023/03/18/opinion/world-bank-climate-change.html', 'https://www.nytimes.com', 'https://www.nytimes.com/2023/03/16/opinion/ezra-klein-podcast-noah-smith.html', 'https://www.nytimes.com/section/sports', 'https://www.nytimes.com/wirecutter/', 'https://theathletic.com/tag/womens-ncaa-tournament/', 'https://www.nytimes.com/2023/03/18/world/europe/ukraine-grain-deal-un-russia.html', 'https://www.nytimes.com/section/opinion', 'https://www.nytimes.com/2023/03/17/opinion/liberal-catholicism.html', 'https://www.nytimes.com/2023/03/17/us/wyoming-abortion-pills-ban.html', 'https://www.nytimes.com/2023/03/17/sports/ncaabasketball/ncaa-womens-basketball-uconn.html', 'https://www.nytimes.com/section/world', 'https://www.nytimes.com/2023/03/18/briefing/spring-returns.html', 'https://www.nytimes.com/interactive/2023/03/14/sports/ncaabasketball/march-madness-bracket-odds-game.html', 'https://help.nytimes.com/hc/en-us/articles/115014792127-Copyright-notice', 'https://help.nytimes.com/hc/en-us/articles/115015727108-Accessibility', 'https://www.tbrandstudio.com/', 'https://www.nytimes.com/sitemap/', 'https://www.nytimes.com/2023/03/18/opinion/womens-health-care.html', 'https://www.nytimes.com/interactive/2023/sports/ncaabasketball/march-madness-womens-bracket.html', 'https://www.nytimes.com/2023/03/18/opinion/svb-banks-change.html', 'https://www.nytimes.com/privacy/cookie-policy#how-do-i-manage-trackers', 'https://www.nytimes.com/interactive/2023/03/18/business/why-people-are-worried-about-banks.html', 'https://help.nytimes.com/hc/en-us/articles/115014893428-Terms-of-service', 'https://www.nytimes.com/2023/03/18/arts/television/lance-reddick-tv-shows-movies.html', 'https://theathletic.com/', 'https://www.nytimes.com/2023/03/16/movies/rimini-review.html', 'https://www.nytimes.com/section/food', 'https://www.nytimes.com/2023/03/18/world/europe/ukraine-emotional-toll-crying.html', 'https://www.nytimes.com/section/us', 'https://www.nytimes.com/2023/03/17/world/europe/simone-segouin-dead.html', 'https://www.nytimes.com/2023/03/17/opinion/jay-clayton-gary-cohn-regulation-silicon-valley-bank.html', 'https://www.nytimes.com/2023/03/17/health/covid-origins-who.html', 'https://www.nytimes.com/', 'https://www.nytimes.com/2023/03/18/business/silicon-valley-bank-collapse.html', 'https://theathletic.com/4235767/2023/03/17/cam-chris-abbott-rogle-shl-sweden/', 'https://www.nytimes.com/puzzles/tiles', 'https://www.nytimes.com/international/?action=click&region=Footer&pgtype=Homepage', 'https://www.nytimes.com/section/books', 'https://www.nytimes.com/2023/03/18/world/canada/trudeau-canada-china-election-meddling.html', 'https://www.nytimes.com/section/magazine', 'https://www.nytimes.com/newsletters/on-college-basketball', 'https://help.nytimes.com/hc/en-us', 'https://www.nytimes.com/games/wordle/index.html', 'https://www.nytimes.com/2022/09/01/crosswords/wordle-starting-words-adieu.html', 'https://www.nytco.com/', 'https://www.nytimes.com/2023/03/18/arts/music/taylor-swift-eras-tour-review.html', 'https://www.nytimes.com/2023/03/16/opinion/poverty-abolition-united-states.html', 'https://www.nytimes.com/2023/03/18/us/politics/republicans-2024-iowa.html', 'https://www.nytimes.com/news-event/ncaa-march-madness', 'https://www.nytimes.com/2023/03/18/sports/ncaabasketball/march-madness-saturday.html', 'https://www.nytimes.com/2023/03/17/opinion/covid-19-pandemic-masks-china.html', 'https://www.nytimes.com/2023/03/17/science/animal-cafes-japan-endangered.html', 'https://theathletic.com/4321276/2023/03/17/john-carlson-capitals-injury/', 'https://www.nytimes.com/interactive/2023/03/12/sports/ncaabasketball/march-madness-mens-bracket.html', 'https://www.nytimes.com/2023/03/16/movies/inside-review-willem-dafoe.html', 'https://www.nytimes.com/2023/03/18/opinion/tiktok-ban-china-spying.html', 'https://www.nytimes.com/2023/03/18/world/europe/macron-pension-future.html', 'https://www.nytimes.com/2023/03/16/books/review/still-life-with-bones-alexa-hagerty.html', 'https://theathletic.com/4320873/2023/03/17/christian-pulisic-gregg-berhalter-usmnt/', 'https://www.nytimes.com/2023/03/17/opinion/nhs-britain-privatization.html', 'https://www.nytimes.com/interactive/2023/03/17/briefing/17news-quiz.html', 'https://www.nytimes.com/2023/03/18/world/middleeast/iraq-war-20th-anniversary.html', 'https://theathletic.com/4320463/2023/03/17/womens-ncaa-tournament-day-1-takeaways/', 'https://www.nytimes.com/section/realestate', 'https://www.nytimes.com/2023/03/18/nyregion/ariel-palitz-nyc-nightlife.html', 'https://theathletic.com/4305862/2023/03/15/mlb-broadcasters-pitch-clock-new/', 'https://www.nytimes.com/2023/03/18/opinion/cancer-brain-mind-body.html', 'https://www.nytimes.com/section/health', 'https://www.nytimes.com/2023/03/16/health/babesiosis-tick-disease-northeast.html', 'https://www.nytimes.com/ca/?action=click&region=Editions&pgtype=Homepage', 'https://help.nytimes.com/hc/en-us/articles/115014893968-Terms-of-sale', 'https://www.nytimes.com/2023/03/17/opinion/silicon-valley-bank-federal-reserve.html', 'https://www.nytimes.com/2023/03/18/business/dealbook/banking-crisis-svb.html', 'https://www.nytimes.com/2023/03/18/us/politics/trump-indictment-arrest-protests.html', 'https://www.nytimes.com/2023/03/18/world/asia/imran-khan-pakistan-court.html', 'https://www.nytimes.com/section/politics', 'https://www.nytimes.com/section/business', 'https://www.nytimes.com/2023/03/17/opinion/walgreens-abortion-pill-attorneys-general-states.html'}\n"
     ]
    }
   ],
   "source": [
    "targetlink = ['https://www.nytimes.com']\n",
    "for i in targetlink :\n",
    "    web = spyder(targetlink,i,1)\n",
    "    print(web.get_crawler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor = conn.cursor()\n",
    "\n",
    "# cursor.execute(\"DROP TABLE Temp_Link;\")\n",
    "# cursor.execute(\"DROP TABLE Domain_Link;\")\n",
    "\n",
    "# conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "no such table: domain_link",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[39mif\u001b[39;00m j\u001b[39m.\u001b[39mstartswith(k):\n\u001b[1;32m     13\u001b[0m                 conn\u001b[39m.\u001b[39mexecute(\u001b[39m'\u001b[39m\u001b[39mUPDATE documents SET REF = ? WHERE link = ? \u001b[39m\u001b[39m'\u001b[39m, (ref[k], j,))\n\u001b[0;32m---> 15\u001b[0m update_ref()    \n",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m, in \u001b[0;36mupdate_ref\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_ref\u001b[39m():\n\u001b[1;32m      2\u001b[0m     conn \u001b[39m=\u001b[39m sqlite3\u001b[39m.\u001b[39mconnect(\u001b[39m'\u001b[39m\u001b[39m../Week10/inverted_index2.db\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     domain \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mexecute(\u001b[39m\"\u001b[39;49m\u001b[39mSELECT domain_link FROM domain_link ;\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mfetchall()\n\u001b[1;32m      4\u001b[0m     domain \u001b[39m=\u001b[39m [t[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m domain]\n\u001b[1;32m      5\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m domain :\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: domain_link"
     ]
    }
   ],
   "source": [
    "def update_ref():\n",
    "    conn = sqlite3.connect('../Week10/inverted_index2.db')\n",
    "    domain = conn.execute(\"SELECT domain_link FROM domain_link ;\").fetchall()\n",
    "    domain = [t[0] for t in domain]\n",
    "    for i in domain :\n",
    "        web = spyder(domain,i,1)\n",
    "        ref = web.get_check_ref()\n",
    "    check_link = conn.execute(\"SELECT link FROM documents ;\").fetchall()\n",
    "    check_link = [t[0] for t in check_link]\n",
    "    for j in check_link:\n",
    "        for k in ref:\n",
    "            if j.startswith(k):\n",
    "                conn.execute('UPDATE documents SET REF = ? WHERE link = ? ', (ref[k], j,))\n",
    "    \n",
    "update_ref()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Crawl_to_temp(target_links,db):\n",
    "    conn = sqlite3.connect(db)\n",
    "    for i in target_links:\n",
    "        domain = conn.execute(\"SELECT id FROM domain_link  WHERE domain_link  = ?\", (i,)).fetchone()\n",
    "        if not domain:\n",
    "            conn.execute(\"INSERT INTO domain_link (domain_link) VALUES (?)\", (i,))\n",
    "        web_spyder = spyder(target_links,i,1)\n",
    "        domainlinks  = web_spyder.get_check_domain()\n",
    "        for link in domainlinks:\n",
    "            conn.execute('''INSERT INTO Temp_link (Link) VALUES (?);''', (link,))\n",
    "            conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Thai:\n",
    "    def __init__(self,data:list):\n",
    "        self.data_value = data\n",
    "        self.sentence = self.get_sentence()\n",
    "        self.summarize = self.get_summarize()\n",
    "        self.word = self.get_word() \n",
    "    def make_sentence(self,list_word):\n",
    "        list_word = [list_word]\n",
    "        self.sentence_value = ''\n",
    "        for i in list_word:\n",
    "            for i in list_word:\n",
    "                if pythainlp.util.countthai(i)<10:\n",
    "                    list_word.remove(i)\n",
    "        self.sentence_value = ' '.join(list_word)\n",
    "        return self.sentence_value\n",
    "    def get_sentence(self):\n",
    "        self.sentence_result = self.make_sentence(self.data_value)\n",
    "        return self.sentence_result\n",
    "    def get_word(self):\n",
    "        self.word_value = tokenizer(self.sentence, engine=\"newmm\")\n",
    "        return self.word_value\n",
    "    def get_summarize(self):\n",
    "        self.summarize_result =[]\n",
    "        self.summarize_result = summarize(self.sentence,n=5)\n",
    "        return self.summarize_result\n",
    "    def location(self):\n",
    "        self.data = self.get_tokenize()\n",
    "        self.location_value = tag_provinces(self.data)\n",
    "        self.Result_location = [entry for entry in self.location_value if entry[1] == 'B-LOCATION']\n",
    "        return self.Result_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_process(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    \n",
    "#Tokenization and lemmatization \n",
    "    lemma_list = []\n",
    "    for token in doc:\n",
    "        lemma_list.append(token.lemma_)\n",
    "    #print(\"Tokenize+Lemmatize:\")\n",
    "    #print(lemma_list)\n",
    "    \n",
    "    #Filter the stopword\n",
    "    filtered_sentence =[] \n",
    "    for word in lemma_list:\n",
    "        lexeme = nlp.vocab[word]\n",
    "        if lexeme.is_stop == False:\n",
    "            filtered_sentence.append(word) \n",
    "    \n",
    "    #Remove punctuation\n",
    "    punctuations=\"?:!.,;\"\n",
    "    for word in filtered_sentence:\n",
    "        if word in punctuations:\n",
    "            filtered_sentence.remove(word)\n",
    "    #print(\" \")\n",
    "    #3print(\"Remove stopword & punctuation: \")\n",
    "    #print(filtered_sentence)\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing(body):\n",
    "    for i in body:\n",
    "        output = i.replace('\\n', '  ').replace('\\xa0', '  ').replace('®', ' ').replace(';', ' ')\n",
    "        output = \" \".join(output.split())\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tags(url):\n",
    "  response = requests.get(url)\n",
    "  soup = BeautifulSoup(response.text, 'html.parser')\n",
    "  try:\n",
    "    title_tag = soup.find('title').text\n",
    "  except:\n",
    "    title_tag = soup.find('title')\n",
    "  try:\n",
    "    body_tag = soup.find('body')\n",
    "    text_below_body = body_tag.get_text().lower()\n",
    "  except:\n",
    "    text_below_body = 'not found'\n",
    "  body_list =[]\n",
    "  body_list.append(text_below_body)\n",
    "  return (body_list,title_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"\\nskip to contentsectionssearchu.s.internationalcanadaespañol中文\\xa0today’s paperworldu.s.politicsn.y.businessopinionsciencehealthsportsartsbooksstylefoodtravelmagazinereal estatecookingthe athleticwirecuttergamesworldu.s.politicsn.y.businessopinionsciencehealthsportsartsbooksstylefoodtravelmagazinereal estatecookingthe athleticwirecuttergames20 years after u.s. invasion, iraq is a freer place, but not a hopeful oneconversations with dozens of iraqis offer a portrait of a nation that is rich in oil, hobbled by corruption and unable to guarantee its citizens’ safety.9 min readjoao silva/the new york timessergey ponomarev for the new york timesjoao silva/the new york timesjoao silva/the new york timesjoao silva/the new york timesjoao silva/the new york timesadvertisementcontinue reading the main storywhy people are worried about banksto understand why some banks seem to be in precarious financial positions, first start with how they fundamentally operate.karl russell/the new york times48 hours till payroll, $200,000 to go: diary of a bank failurethe collapse of silicon valley bank set major financial disruptions in motion. it also made one start-up founder’s week a scramble.11 min readdealbook: how should regulations change in the wake of silicon valley bank’s collapse? here are two big ideas.6 min readtrump says his arrest is imminent and calls for protests, echoing jan. 6former president trump claimed that he would be arrested on tuesday. his indictment by a manhattan grand jury is expected, but its timing is unclear.6 min readdesiree rios/the new york timesanalysis: macron faces an angry france alonepresident emmanuel macron saw his decision to ram through a change in the retirement age as necessary. but the price may be high.5 min readmichel euler/agence france-presse — getty imageszoom friends forever?online happy hours and game nights are over. but some people really miss the connections and want to keep the virtual get-togethers going.9 min readillustration by antoine doréin stoic ukraine, stony faces are starting to crack and to cryalthough ukrainians excel at putting up a brave front, a tremendous amount of suffering is being kept bottled up and sometimes bursts out.4 min reademile ducke for the new york timespresident vladimir putin made a surprise visit to crimea on the anniversary of russia’s illegal annexation of the peninsula.4 min readfor trump and his potential 2024 g.o.p. rivals, it’s all about iowaas former vice president mike pence visits on saturday, iowa has become pivotal for possible contenders, and for former president trump in particular.5 min readhaiyun jiang/the new york times\\n\\nn.c.a.a. tournamentmen’s bracketwomen’s bracketprediction game resultsnewsletterfrom the athletic: men\\xa0| womenlive updates from the athletic: furman to face san diego stateby the end of saturday’s second-round games, half of the sweet 16 will be set. follow here for insights, news and analysis.no. 16 seed fairleigh dickinson took down top-seeded purdue on friday, delivering a shocking n.c.a.a. tournament upset.6 min readdylan buell/getty imageshere are the saturday games we don’t want to miss.3 min readfrom the athleticsign in to the athletic with your new york times account to read more.princeton made ivy league history, and more takeaways from day 1 of the women’s tournament.after a fun first round, here’s a game-by-game look at today’s potential upsets.last call for new york’s first ‘bar czar’as ariel palitz leaves her role, she reflects on what she discovered about the city, and about herself.5 min readmichelle v. agins/the new york timesthe weekender: seaweed is having its moment in the sunalso in this edition: the brilliant inventor who made two of history’s biggest mistakes, and at long last, a donkey family tree.did you follow the news this week? take our quiz.what to watch and read this weekendadvertisementcontinue reading the main storypaul schiraldiwatch lance reddick’s best performancesthe actor, who died on friday, brought gravitas to series like “the wire” and “bosch,” but he also subverted his image in comic roles.3 min readtaylor swift highlighted how many pivots her career has taken on her recent tour, our critic writes.5 min reada reader asks the ethicist about an ex who will not delete sensitive family photos.5 min readopinionezra kleinchange makes fools of us all7 min readphoto illustration by justin metzthe editorial boardthe world bank needs to adapt to a changing world4 min readnicholas kristofhe’s the world’s most popular leader. beware.4 min readpeter harrell and tim wubeing an open and democratic country does not mean being a sucker5 min readjessica grosewomen’s health care is still underfunded. the consequences are dire.4 min readdavid j. lindencan a neuroscientist fight cancer with mere thought?6 min readjay clayton and gary cohnstop the partisan bickering. we need smart solutions to save our banking system.6 min readdavid wallace-wellsamerica has decided it went overboard on covid-199 min readmary zieglerif you want to know what republicans think about how americans feel, ask walgreens5 min readletters from our readersare colleges too ‘woke’ and alienating conservatives?5 min readross douthatwhat liberal catholicism gets right9 min read‘the ezra klein show’why silicon valley bank collapsed — and what comes nextbruce a. green and david udellwhat’s wrong with getting a little free legal advice?5 min readpeter coythe fed’s balance sheet looks like silicon valley bank’s6 min readallyson pollock and peter roderickyou don’t have to be a doctor to know how much trouble the n.h.s. is in5 min readmatthew desmondamerica is in a disgraced category of its own8 min readread the morning newslettermelissa kirsch on spring’s arrival, its adherents and its detractors.7 min readthe week in reporter readshere are five narrated stories from around the times, including a racism controversy at a law school and a life-changing phone call.in case you missed ittop picks from the times, recommended for youadvertisementcontinue reading the main storymore newswyoming becomes first state to outlaw the use of pills for abortionmedication abortion providers could serve six months in prison under the law, one of the latest efforts by conservative states to target the pills.6 min readclaims of chinese election meddling put trudeau on defensiveprime minister justin trudeau of canada is battling critics and reports that opponents say show he had ignored warnings of chinese interference.5 min readchaos breaks out as imran khan makes court appearancesupporters of the former prime minister of pakistan have repeatedly clashed this week with the authorities, keeping the country on edge.5 min readfacing extinction, but available for selfies in japan’s animal cafesresearchers identified critically endangered species of birds, reptiles and mammals at dozens of the cafes.5 min readnoriko hayashi for the new york timesw.h.o. accuses china of hiding data that may link covid origins to animals5 min readpolice in new jersey pleaded with a man in crisis. then they shot him.5 min readsimone segouin, teenage fighter in french resistance, dies at 974 min readthere’s another tick disease to worry about in the northeast, c.d.c says3 min readjim gordon, top rock drummer with a troubled life, dies at 775 min readmet opera ordered to pay anna netrebko $200,000 for canceled performances4 min readwellculture and lifestylea tenor’s secrets to ‘lohengrin’: golf and a blunt spousepiotr beczala, known as a charismatic singer of italian operas, is challenging notions of what a wagner voice should sound like.vincent tullo for the new york timesis the uconn dynasty a thing of the past?the wealth of talent in women’s basketball is deepening across the n.c.a.a.5 min readhearing what the dead have to sayin “still life with bones,” alexa hagerty recounts her training in exhumation.4 min read‘inside’ review: tortured artist, meet tortured manwillem dafoe stars as an art thief who gets trapped in a penthouse.3 min read‘rimini’ review: just an austrian gigoloulrich seidl’s unsettling drama is about an aging lounge singer.3 min readadvertisementcontinue reading the main storythe athleticsign in to the athletic with your new york times account to read more.baseball’s new pitch clock waits for no one, including broadcasterseven m.l.b.’s most experienced voices are adjusting to a whole new ballgame.ron vesely/getty imagesafter edwin diaz’s freak injury, the mets still have hopethe pitcher faces an arduous road, but there’s still a slight chance he could return to the mound in time for a potential world series run.the twin brothers capturing the hockey world’s attentionin a small swedish city, the pair have transformed a club and its players. could they do the same in the n.h.l.?n.h.l. player nears return after getting hit with 90 m.p.h. slap shotwhat christian pulisic’s comments on gregg berhalter revealthe top 10 n.f.l. free agents still available and the teams they could helpnew york times cookingrecipes, advice and inspiration for any occasion.recommendations from wirecutterindependent reviews for thousands of products.advertisementcontinue reading the main storynew york times gamesdaily word and visual games, plus more.wordleguess the 5-letter word with 6 chances.the best first wordle wordswhat the data tells us about how people play the game.3 min readspelling beehow many words can you make with 7 letters?the crosswordget clued in with wordplay, every day.letter boxedcreate words using letters around the square.tilesmatch visual elements and keep your chain going.site indexnewshome pageworldcoronavirusu.s.politicsnew yorkbusinesstechscienceclimatesportswildfire trackerobituariesthe upshotinternationalcanadaespañol中文网today's papercorrectionstrendingopiniontoday's opinioncolumnistseditorialsguest essaysletterssunday opinionopinion videoartstoday's artsart & designbooksbest sellers book listdancemoviesmusicpop culturetelevisiontheaterwhat to watchvideo: artslivingautomotivegameseducationfoodhealthjobslovemagazineparentingreal estatestylet magazinetravellistings & morereader centerthe athleticwirecuttercookingheadwaylive eventsthe learning networktools & servicespodcastsvideographicstimesmachinetimes storemanage my accountnytlicensingnewshome pageworldcoronavirusu.s.politicsnew yorkbusinesstechscienceclimatesportswildfire trackerobituariesthe upshotinternationalcanadaespañol中文网today's papercorrectionstrendingopiniontoday's opinioncolumnistseditorialsguest essaysletterssunday opinionopinion videoartstoday's artsart & designbooksbest sellers book listdancemoviesmusicpop culturetelevisiontheaterwhat to watchvideo: artslivingautomotivegameseducationfoodhealthjobslovemagazineparentingreal estatestylet magazinetravelmorereader centerthe athleticwirecuttercookingheadwaylive eventsthe learning networktools & servicespodcastsvideographicstimesmachinetimes storemanage my accountnytlicensingsubscribehome deliverydigital subscriptionsgamescookingemail newsletterscorporate subscriptionseducation ratemobile applicationsreplica editioninternationalcanadaespañol中文网site information navigation©\\xa02023\\xa0the new york times companynytcocontact usaccessibilitywork with usadvertiset brand studioyour ad choicesprivacy policyterms of serviceterms of salesite mapcanadainternationalhelpsubscriptions\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\"],\n",
       " 'The New York Times - Breaking News, US News, World News and Videos')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_tags('https://www.nytimes.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(body):\n",
    "    word_freq = {}\n",
    "    for word in body:\n",
    "        if word in word_freq:\n",
    "            word_freq[word] += 1\n",
    "        else:\n",
    "            word_freq[word] = 1\n",
    "    return word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize as thaitokenize , pos_tag, ne_chunk\n",
    "from nltk import Tree\n",
    "\n",
    "def get_continuous_chunks(text,label):\n",
    "    chunked = ne_chunk(pos_tag(thaitokenize(text)))\n",
    "    prev = None\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for subtree in chunked:\n",
    "        if type(subtree) == Tree and subtree.label() == label:\n",
    "            current_chunk.append(\" \".join([token for token, pos in subtree.leaves()]))\n",
    "        if current_chunk:\n",
    "            named_entity = \" \".join(current_chunk)\n",
    "            if named_entity not in continuous_chunk:\n",
    "                continuous_chunk.append(named_entity)\n",
    "                current_chunk = []\n",
    "        else:\n",
    "            continue\n",
    "    if continuous_chunk ==[]:\n",
    "        return 'None'\n",
    "\n",
    "    else:\n",
    "        return continuous_chunk\n",
    "\n",
    "def eng_location(doc):\n",
    "    return get_continuous_chunks(doc[0], 'GPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_lang(url:str):\n",
    "    data_lang,title = scrape_tags(url)\n",
    "    try:\n",
    "        percent = pythainlp.util.countthai(data_lang[0][0])\n",
    "        if percent >50:\n",
    "            thai_nlp = Thai(data_lang[0]) \n",
    "            word = thai_nlp.word\n",
    "            try:\n",
    "                location = 'จ.'+max(thai_nlp.get_location().keys())\n",
    "            except:\n",
    "                location = 'Thailand'\n",
    "            new_list = [s.strip().replace('\"', '') for s in word if s.strip()]\n",
    "            while '' in new_list:\n",
    "                new_list.remove('')\n",
    "            word = get_word(new_list)\n",
    "            return data_lang,word,title,location\n",
    "        else:\n",
    "            clean_body=cleansing(data_lang)\n",
    "            body = spacy_process(cleansing(data_lang))\n",
    "            word = get_word(body)\n",
    "            location = eng_location(data_lang)\n",
    "            return clean_body,word,title,location\n",
    "    except:\n",
    "        clean_body=cleansing(data_lang)\n",
    "        body = spacy_process(cleansing(data_lang))\n",
    "        word = get_word(body)\n",
    "        location = eng_location(data_lang)\n",
    "        return clean_body,word,title,location\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_lang('https://www.thairath.co.th/news/crime/2633816')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_lang('https://www.bbc.com/news/world-asia-64957293')[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_doc(link,target_links):\n",
    "    link.replace(\" \", \"\")\n",
    "    d=dict()\n",
    "    body,word,title,location=check_lang(link)\n",
    "    d['link']= link\n",
    "    d['title'] = title\n",
    "    d['body']=body\n",
    "    d['location']=location\n",
    "    d['word'] = word\n",
    "    for k in target_links:\n",
    "        if link.startswith(k):\n",
    "            d['ref'] = target_links[k]\n",
    "    print(d)\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_links = {'http://www.bbc.com':0}\n",
    "for i in target_links:\n",
    "    make_doc(i,target_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc(links,n):\n",
    "    target_links=dict()\n",
    "    for i in links:\n",
    "        target_links[i]=0\n",
    "    doc=[]\n",
    "    num=0\n",
    "    for i in target_links:\n",
    "        web_spyder=spyder(target_links,i,n)\n",
    "        domain_links,target_links =web_spyder.get_all()\n",
    "        print('all link =', len(domain_links))\n",
    "        for j in domain_links:\n",
    "            num+=1\n",
    "            d = make_doc(j,target_links)\n",
    "            doc.append(d)\n",
    "            print(num)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_links=['https://www.bbc.com/news','https://edition.cnn.com','https://www.bangkokpost.com','http://www.thairath.co.th/news',]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = get_doc(target_links,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to SQLite3 database\n",
    "conn = sqlite3.connect('../Week10/inverted_index2.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create tables for words, documents, and word frequencies\n",
    "\n",
    "conn.execute('''\n",
    "CREATE TABLE words (\n",
    "    ID INTEGER PRIMARY KEY,\n",
    "    Word TEXT NOT NULL UNIQUE\n",
    ");\n",
    "''')\n",
    "\n",
    "conn.execute('''\n",
    "CREATE TABLE documents (\n",
    "    ID INTEGER PRIMARY KEY,\n",
    "    Link TEXT NOT NULL UNIQUE ,\n",
    "    Title TEXT,\n",
    "    Body TEXT,\n",
    "    Location TEXT,\n",
    "    Ref INT,\n",
    "    Time TEXT\n",
    ");\n",
    "''')\n",
    "\n",
    "conn.execute('''\n",
    "CREATE TABLE word_frequencies (\n",
    "    Word_ID INTEGER ,\n",
    "    Doc_ID INTEGER ,\n",
    "    Frequency INTEGER NOT NULL,\n",
    "    TF_IDF REAL ,\n",
    "    PRIMARY KEY (word_id, doc_id),\n",
    "    FOREIGN KEY (word_id) REFERENCES words(id),\n",
    "    FOREIGN KEY (doc_id) REFERENCES documents(id)\n",
    ");\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import math\n",
    "def update_tf_idf():\n",
    "    conn = sqlite3.connect('inverted_index.db',timeout=3)\n",
    "\n",
    "    cursor = conn.execute('SELECT COUNT(*) FROM documents')\n",
    "    N = cursor.fetchone()[0]\n",
    "    \n",
    "    cursor = conn.execute('SELECT ID, Word FROM words')\n",
    "    words = cursor.fetchall()\n",
    "    \n",
    "    for word in words:\n",
    "        word_id = word[0]\n",
    "        word_str = word[1]\n",
    "\n",
    "        cursor = conn.execute('SELECT Doc_ID, Frequency FROM word_frequencies WHERE Word_ID = ?', (word_id,))\n",
    "        doc_freqs = cursor.fetchall()\n",
    "\n",
    "        df = len(doc_freqs)\n",
    "        idf = math.log(N / df)\n",
    "\n",
    "        for doc_freq in doc_freqs:\n",
    "            doc_id = doc_freq[0]\n",
    "            tf = doc_freq[1]\n",
    "            tf_idf = tf * idf\n",
    "            conn.execute('UPDATE word_frequencies SET TF_IDF = ? WHERE Word_ID = ? AND Doc_ID = ?', (tf_idf, word_id, doc_id))\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_tf_idf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_to_database(doc):\n",
    "  conn = sqlite3.connect('../Week10/inverted_index2.db')\n",
    "  for i in doc:\n",
    "    conn.execute('''INSERT INTO documents (Link, Title, Body, Location, Ref, Time) VALUES (?, ?, ?, ?, ?, ?);''', (str(i['link']), str(i['title']), str(i['body']), str(i['location']), int(i['ref']), datetime.now()))\n",
    "    doc_id = conn.execute(\"SELECT last_insert_rowid()\").fetchone()[0]\n",
    "    \n",
    "    for j in i['word'].keys():\n",
    "      word_id = conn.execute(\"SELECT id FROM words WHERE word = ?\", (j,)).fetchone()\n",
    "      if not word_id:\n",
    "        conn.execute(\"INSERT INTO words (word) VALUES (?)\", (j,))\n",
    "        word_id = conn.execute(\"SELECT last_insert_rowid()\").fetchone()[0]\n",
    "      else:\n",
    "        word_id = word_id[0]\n",
    "      \n",
    "      conn.execute('''INSERT INTO word_frequencies (word_id, doc_id, Frequency) VALUES (?, ?, ?);''', (word_id, doc_id, i['word'][j]))\n",
    "  \n",
    " \n",
    "    \n",
    "  conn.commit()\n",
    "  update_tf_idf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_to_database(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_data(link):\n",
    "    db_dir = '../Week10/inverted_index2.db'\n",
    "    conn = sqlite3.connect(db_dir,timeout=10)\n",
    "    doc_id = conn.execute('''\n",
    "    SELECT id FROM documents WHERE link = ?; ''', (link,)).fetchone()[0]\n",
    "    conn.execute('''\n",
    "        DELETE FROM documents WHERE link = ?; ''', (link,))\n",
    "\n",
    "    conn.execute('''\n",
    "        DELETE FROM word_frequencies WHERE Doc_ID = ?;''', (doc_id,))\n",
    "\n",
    "    conn.execute('''\n",
    "        DELETE FROM words\n",
    "        WHERE NOT EXISTS (SELECT 1 FROM word_frequencies WHERE word_frequencies.word_id = words.id );''')\n",
    "    \n",
    "    conn.commit()\n",
    "    update_tf_idf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'link':'wwww.','title':'asdasd','body':'asdasd',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_data(link):\n",
    "    db_dir = '../Week10/inverted_index2.db'\n",
    "    conn = sqlite3.connect(db_dir,timeout=10)\n",
    "    target_links={}\n",
    "    for i in link:\n",
    "        target_links[link]=0\n",
    "    for i in target_links:\n",
    "        get_link = spyder(target_links,i,2)\n",
    "        domain_link,target_links = get_link.get_all()\n",
    "    for j in domain_link:\n",
    "        link = conn.execute('''SELECT  documents.link\n",
    "                                    FROM documents\n",
    "                                    WHERE documents.link = ?\n",
    "                                    ''',(j,)) \n",
    "        link = link.fetchone()\n",
    "        doc = [make_doc(j,target_links)]\n",
    "        if link == None :\n",
    "            print(j)\n",
    "            insert_to_database(doc)\n",
    "        else:\n",
    "            print(j)\n",
    "            delete_data(j)\n",
    "            insert_to_database(doc)\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_data('https://www.bbc.com/news',3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [str(input())]\n",
    "clean_sentence = cleansing(sentence)\n",
    "word = spacy_process(clean_sentence)\n",
    "print(clean_sentence)\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search():\n",
    "    conn = sqlite3.connect('../Week10/inverted_index2.db')\n",
    "    cursor = conn.cursor()\n",
    "    search_term = [str(input())]\n",
    "    clean_sentence = cleansing(search_term)\n",
    "    words = spacy_process(clean_sentence)\n",
    "    doc_lists = []\n",
    "    for word in words:\n",
    "        cursor.execute('SELECT Doc_ID FROM word_frequencies WHERE Word_ID = (SELECT ID FROM words WHERE Word = ?)', (word,))\n",
    "        doc_lists.append(set(doc[0] for doc in cursor.fetchall()))\n",
    "\n",
    "    # Find the documents that contain all the words in the sentence\n",
    "    matching_docs = set.intersection(*doc_lists)\n",
    "\n",
    "    # Calculate the score for each document\n",
    "    scores = {}\n",
    "    for doc_id in matching_docs:\n",
    "        score = sum(cursor.execute('SELECT Frequency FROM word_frequencies WHERE Word_ID = (SELECT ID FROM words WHERE Word = ?) AND Doc_ID = ?', (word, doc_id)).fetchone()[0] for word in words)\n",
    "        scores[doc_id] = score\n",
    "\n",
    "    # Sort the documents by score in descending order\n",
    "    sorted_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the list of document links\n",
    "    doc_links = []\n",
    "    for doc_id, score in sorted_docs:\n",
    "        cursor.execute('SELECT Link, title FROM documents WHERE ID = ?', (doc_id,))\n",
    "        doc_links.append(cursor.fetchone()[0])\n",
    "        \n",
    "    \n",
    "            \n",
    "\n",
    "    # Close the database connection and return the list of document links\n",
    "    conn.close()\n",
    "    print(search_term)\n",
    "    return doc_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import math\n",
    "\n",
    "def search_sentence():\n",
    "    conn = sqlite3.connect('../Week10/inverted_index2.db')\n",
    "    cursor = conn.cursor()\n",
    "    search_term = str(input())\n",
    "    list_term = [search_term]\n",
    "    clean_sentence = cleansing(list_term)\n",
    "    words = spacy_process(clean_sentence)\n",
    "\n",
    "    # Retrieve the word IDs for each word in the sentence\n",
    "    word_ids = []\n",
    "    for word in words:\n",
    "        cursor.execute('SELECT word_ID FROM words WHERE word = ?', (word,))\n",
    "        result = cursor.fetchone()\n",
    "        if result:\n",
    "            word_ids.append(result[0])\n",
    "\n",
    "    # Join the word_frequencies and documents tables to get the documents that contain any of the words in the sentence\n",
    "    cursor.execute('''\n",
    "        SELECT documents.Link, documents.Title, SUM(word_frequencies.TF_IDF)\n",
    "        FROM word_frequencies\n",
    "        JOIN documents ON documents.ID = word_frequencies.Doc_ID\n",
    "        WHERE word_frequencies.Word_ID IN ({})\n",
    "        GROUP BY documents.ID\n",
    "        ORDER BY SUM(word_frequencies.TF_IDF) DESC\n",
    "    '''.format(','.join(str(id) for id in word_ids)))\n",
    "\n",
    "    # Get the document links and titles for the top results\n",
    "    results = cursor.fetchall()\n",
    "    print('search term : ',search_term)\n",
    "    print('search result: ')\n",
    "    for result in results:\n",
    "        print(result[0], result[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import math\n",
    "\n",
    "def sentence_search():\n",
    "    conn = sqlite3.connect('inverted_index.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Split the query into individual words\n",
    "    search_term = [str(input())]\n",
    "    clean_sentence = cleansing(search_term)\n",
    "    words = spacy_process(clean_sentence)\n",
    "\n",
    "    # Retrieve the documents that contain each word\n",
    "    doc_lists = []\n",
    "    for word in words:\n",
    "        cursor.execute(\"SELECT Doc_ID, TF_IDF FROM word_frequencies JOIN words ON words.ID = word_frequencies.word_ID WHERE word = ?\", (word,))\n",
    "        doc_list = cursor.fetchall()\n",
    "        doc_lists.append(doc_list)\n",
    "\n",
    "    # Merge the document lists using the TF-IDF scores\n",
    "    doc_scores = {}\n",
    "    for doc_list in doc_lists:\n",
    "        for doc_id, tf_idf in doc_list:\n",
    "            if doc_id in doc_scores:\n",
    "                doc_scores[doc_id] += tf_idf\n",
    "            else:\n",
    "                doc_scores[doc_id] = tf_idf\n",
    "\n",
    "    # Rank the documents by their overall relevance\n",
    "    ranked_docs = sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Retrieve the links and titles of the top documents\n",
    "    results = []\n",
    "    for doc_id, score in ranked_docs:\n",
    "        cursor.execute(\"SELECT location FROM documents WHERE ID = ?\", (doc_id,))\n",
    "        location = cursor.fetchone()\n",
    "        results.append((location))\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"['Tunisia', 'Nigeria', 'Mali', 'Ethiopia', 'South Africa', 'Ukraine', 'Mozambique', 'Malawi', 'South Sudan', 'Kenya', 'Botswana', 'Turkey', 'Ghana']\",),\n",
       " (\"['Uruguay', 'Spain', 'Portugal', 'Malta', 'Israel', 'Tunisia', 'Malaysia', 'Turkey', 'South Africa', 'Greece', 'Egypt', 'Italy', 'Libya', 'Paraguay', 'Rwanda', 'Argentina', 'Chile', 'Iraq', 'Qatar', 'Morocco']\",),\n",
       " (\"['Brazil']\",),\n",
       " (\"['Ukraine', 'France', 'Italy', 'Japan', 'India', 'Australia']\",),\n",
       " (\"['Australia', 'Ireland']\",),\n",
       " (\"['Sweden', 'United States', 'Ukraine', 'France', 'Italy', 'Kenya', 'China', 'Poland', 'Turkey', 'Finland']\",),\n",
       " (\"['Ukraine', 'France', 'Italy', 'Japan', 'India', 'Australia']\",),\n",
       " (\"['Ukraine', 'Ghana', 'Turkey']\",),\n",
       " (\"['Malawi']\",),\n",
       " (\"['France', 'Italy', 'Japan', 'India', 'Australia']\",),\n",
       " (\"['Ireland', 'Turkey', 'Canada', 'Madagascar', 'Finland']\",),\n",
       " (\"['Ireland', 'China', 'India', 'Canada', 'Australia', 'Pakistan']\",),\n",
       " (\"['France', 'Italy', 'Japan', 'India', 'Australia']\",),\n",
       " (\"['China', 'India']\",),\n",
       " (\"['None']\",),\n",
       " (\"['Australia', 'Singapore']\",),\n",
       " (\"['France', 'Japan', 'India', 'Ukraine', 'Australia', 'Italy']\",),\n",
       " (\"['France', 'Japan', 'India', 'Ukraine', 'Australia', 'Italy']\",),\n",
       " (\"['Ukraine', 'France', 'Italy', 'Japan', 'India', 'Australia', 'Croatia']\",),\n",
       " (\"['France', 'Italy', 'China', 'Japan', 'India', 'Australia']\",),\n",
       " (\"['Nigeria', 'Ukraine', 'France', 'Indonesia', 'Italy', 'Romania', 'Japan', 'India', 'Australia', 'Colombia']\",),\n",
       " (\"['None']\",),\n",
       " (\"['Ukraine', 'France', 'Italy', 'Japan', 'India', 'Australia']\",),\n",
       " (\"['France', 'Italy', 'Japan', 'India', 'Australia']\",),\n",
       " (\"['Iraq']\",),\n",
       " (\"['Switzerland', 'Ukraine', 'Libya', 'China', 'Canada', 'Ghana']\",),\n",
       " (\"['None']\",),\n",
       " (\"['None']\",),\n",
       " (\"['Tunisia', 'South Africa', 'Malawi', 'Kenya', 'Mauritania', 'Ghana']\",)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_search()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
